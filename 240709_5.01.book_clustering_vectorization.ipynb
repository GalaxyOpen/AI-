{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **워드 임베딩 + 클러스터링**"
      ],
      "metadata": {
        "id": "XUeB-JMPq4N9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EJcLm3HZPUn"
      },
      "outputs": [],
      "source": [
        "# 기본 패키지 불러오기\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "95gTmoMYqJgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 파일 불러오기\n",
        "df_1 = pd.read_csv('/content/book.csv', encoding='euc-kr')\n",
        "\n",
        "# df_1.head()"
      ],
      "metadata": {
        "id": "4vvaLUSXaQER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_1.tail()"
      ],
      "metadata": {
        "id": "gd3aV8noalpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리 - price  object => 수치형\n",
        "# df['Price'] = pd.to_numeric(df['Price'].str.replace('[^\\d.]', ''), errors='coerce')\n",
        "\n",
        "# 'Pdate' 컬럼을 날짜 타입으로 변환 (한국어 날짜 형식에 맞춤)\n",
        "# df['Pdate'] = pd.to_datetime(df['Pdate'], format='%Y년 %m월 %d일', errors='coerce')\n"
      ],
      "metadata": {
        "id": "mhbUTwTgboXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리 - 공백 제거\n",
        "df_1 = df_1.dropna(subset=['Title'])\n",
        "df_1 = df_1[df_1['Title'].str.strip() != '']\n",
        "\n",
        "# df_2 = df_1.dropna(subset=['Publisher'])\n",
        "# df_2 = df_2[df_2['Publisher'].str.strip() != '']"
      ],
      "metadata": {
        "id": "p1XIt2FAavk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리 - 언어별 구분\n",
        "# df = df_2[df_1['Title'].str.contains('[A-Za-z]', regex=True)]\n",
        "# 한국어 [가-힣]\n",
        "# 영어[A-Za-z]\n",
        "# 일본어 [ぁ-んァ-ン]\n"
      ],
      "metadata": {
        "id": "sCu5psNtbeQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리 - 언어별 구분\n",
        "import re\n",
        "\n",
        "# 영어 제목만\n",
        "def is_english_title(text):\n",
        "    # 영어 알파벳, 공백, 일부 특수문자(예: ',!?.)만 허용\n",
        "    return bool(re.match(r'^[a-zA-Z0-9 .,\\-\\'!?]+$', text))\n",
        "\n",
        "# 영어로만 구성된 책 제목만 가져옴\n",
        "df_e = df_1[df_1['Title'].apply(is_english_title)]\n",
        "\n",
        "# 한국 제목만\n",
        "def is_korean_title(text):\n",
        "    # 영어 알파벳, 공백, 일부 특수문자(예: ',!?.)만 허용\n",
        "    return bool(re.match(r'^[가-힣0-9 .,\\-\\'!?]+$', text))\n",
        "\n",
        "# 한국어로만 구성된 책 제목만 가져옴\n",
        "df_k = df_1[df_1['Title'].apply(is_korean_title)]\n",
        "\n",
        "\n",
        "## df_k,   df_e  변수명 변경 시... 관련된 부분 모두 수정해 주어야 함"
      ],
      "metadata": {
        "id": "7b1G0rUgu7eL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 벡터화 + 클러스터링을 위한 패키지\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n"
      ],
      "metadata": {
        "id": "NyFZs01CtjJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tf-idf** <br>\n",
        "단어의 출현 빈도 및 상대 빈도 활용"
      ],
      "metadata": {
        "id": "ZDDS9Cv_iABI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(max_features=100) # 전체 단어 집합에서 TF-IDF 값이 가장 높은 상위 n개의 단어만을 선택하여 특성 벡터를 생성\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(df_k)"
      ],
      "metadata": {
        "id": "uPfj1clMiGjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 클러스터링 수행\n",
        "kmeans = KMeans(n_clusters=10, random_state=42)\n",
        "kmeans.fit(X_tfidf)\n",
        "\n",
        "### 이후 아래 #123 코드 셀로 이동하여 코드 실행"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "tJRmthZsjCtw",
        "outputId": "de9b5f4e-9f5b-47dd-c0e9-972afac4715e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(n_clusters=10, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=10, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=10, random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word2Vec** <br>\n",
        "주변단어들을 학습에 사용 <br> <br>\n",
        "CBOW<br>\n",
        "주변 단어들(문맥)-타겟 단어의 앞뒤에 위치한 단어들-을 기반으로 타겟 단어 예측<br>\n",
        "ex \"The cat sits on the ___\" 빈칸에 들어갈 단어(타겟 단어) 예측<br><br>\n",
        "Skip-gram<br>\n",
        "특정 단어를 입력으로 받아, 그 단어 주변의 문맥 단어를 예측<br>\n",
        "ex \"cat\"이라는 단어가 주어졌을 때, 이 단어 주변에 위치할 가능성이 높은 단어(\"The\", \"sits\", \"on\") 예측"
      ],
      "metadata": {
        "id": "OgkONuaOf0C_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################# Word2Vec  #################\n",
        "from gensim.models import Word2Vec\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 책 제목을 단어 리스트로 변환\n",
        "sentences = [title.split() for title in df_k['Title']]\n",
        "\n",
        "# Word2Vec 모델 학습\n",
        "word2vec_model = Word2Vec(sentences, vector_size=64, window=5, min_count=1)\n",
        "   # 책 제목에서 각 단어의 벡터 표현 학습\n",
        "   # 학습을 통해 책 제목을 구성하는 단어들 간의 관계와 문맥을 바탕으로 각 단어의 의미를 반영하는 벡터 생성\n"
      ],
      "metadata": {
        "id": "ueP8q6Tsgi79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 책 제목 -> 벡터값 조회 및 제목단위 평균값 산출\n",
        "# 학습된 word2vec 모델을 사용하여 각 책 제목을 구성하는 단어들의 벡터 값 조회\n",
        "def vectorize_w_word2vec(text):\n",
        "    words = text.split()\n",
        "    word_vectors = [word2vec_model.wv[word] for word in words if word in word2vec_model.wv]\n",
        "    if len(word_vectors) == 0:\n",
        "        return np.zeros(word2vec_model.vector_size)\n",
        "    return np.mean(word_vectors, axis=0)\n",
        "\n",
        "# 각 책 제목을 벡터화\n",
        "title_vectors_k = np.array([vectorize_w_word2vec(title) for title in df_k['Title']])\n",
        "\n",
        "### 이 후 아래 클러스터링 코드 실행하여 결과 확인"
      ],
      "metadata": {
        "id": "7DQIQdbHhNYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FastText** <br>\n",
        "주변 단어들을 학습에 사용 =  word2vec <br>\n",
        "서브 워드 사용 <br>"
      ],
      "metadata": {
        "id": "S-_-s7mofYiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################# FastText  #################\n",
        "from gensim.models import FastText\n",
        "from sklearn.cluster import KMeans\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# FastText 모델 학습 (로컬 데이터)\n",
        "# sentences = [title.split() for title in df_e['Title']]\n",
        "sentences = [title.split() for title in df_k['Title']]\n",
        "fasttext_model = FastText(sentences, vector_size=64, window=5, min_count=1)\n",
        "   # 책 제목에서 각 단어와 서브워드(subword)의 벡터 표현 학습\n",
        "   # 학습을 통해 책 제목을 구성하는 단어들 간의 관계와 문맥을 바탕으로 각 단어의 의미를 반영하는 벡터 생성\n",
        "\n"
      ],
      "metadata": {
        "id": "sL_mN7CEJ4YA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 책 제목 -> 벡터값 조회 및 제목단위 평균값 산출\n",
        "# 학습된 FastText 모델을 사용하여 각 책 제목을 구성하는 단어들의 벡터 값 조회\n",
        "def vectorize_w_fasttext(text):\n",
        "    words = text.split()\n",
        "    word_vectors = [fasttext_model.wv[word] for word in words if word in fasttext_model.wv]\n",
        "    if len(word_vectors) == 0:\n",
        "        return np.zeros(fasttext_model.vector_size)\n",
        "    return np.mean(word_vectors, axis=0)\n",
        "\n",
        "# 제목 벡터화\n",
        "title_vectors_k = np.array([vectorize_w_fasttext(title) for title in df_k['Title']])"
      ],
      "metadata": {
        "id": "cnD5lm9oemEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w-eOgjB3hXWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**아래 클러스터링 과정은 동일**"
      ],
      "metadata": {
        "id": "mAMUaOaYhQ4T"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t2v91e8vhXsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# K-평균 클러스터링 수행\n",
        "kmeans = KMeans(n_clusters=10, random_state=42)\n",
        "kmeans.fit(title_vectors_k)\n",
        "\n",
        "# 클러스터 할당 결과\n",
        "df_k['Cluster'] = kmeans.labels_"
      ],
      "metadata": {
        "id": "CzUNlIsDIkqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 123 코드 셀\n",
        "# 클러스터 별로 데이터 확인\n",
        "for cluster in range(10): # 클러스터의 수에 따라 범위 조정\n",
        "    print(f\"Cluster {cluster}:\")\n",
        "    print(df_k[df_k['Cluster'] == cluster]['Title'].head(), '\\n') # 각 클러스터에 속한 책 제목 출력\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYQULHLbKFb7",
        "outputId": "6c30dd9e-a702-478b-f266-f20c2ff5867a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster 0:\n",
            "409     묻고 답하는 한국사카페 1\n",
            "442         두근두근 중국어 1\n",
            "476          런웨이의 연인 1\n",
            "518      우리에게는 벽이 있다 1\n",
            "520    반쪽 달이 떠오르는 하늘 1\n",
            "Name: Title, dtype: object \n",
            "\n",
            "Cluster 1:\n",
            "1719     쿠키런 서바이벌 대작전 7\n",
            "1738     쿠키런 서바이벌 대작전 2\n",
            "1739     쿠키런 서바이벌 대작전 1\n",
            "1740     쿠키런 서바이벌 대작전 3\n",
            "1768    쿠키런 서바이벌 대작전 16\n",
            "Name: Title, dtype: object \n",
            "\n",
            "Cluster 2:\n",
            "25         이화림 회고록\n",
            "126         경영의 명의\n",
            "191         척추영상진단\n",
            "192    건축견적이야기 세트 \n",
            "262    가족신탁 이론과 실무\n",
            "Name: Title, dtype: object \n",
            "\n",
            "Cluster 3:\n",
            "98                         창의적 공학설계\n",
            "165              4차 산업혁명 시대의 운영관리혁신\n",
            "173                       알기쉬운 해부생리\n",
            "277    유패스 지텔프 최신 기출유형 공식 기본서 문법 독해\n",
            "342                       프랑스 엄마 수업\n",
            "Name: Title, dtype: object \n",
            "\n",
            "Cluster 4:\n",
            "1851    수학도둑 39\n",
            "1867    수학도둑 50\n",
            "1868    수학도둑 41\n",
            "1904    수학도둑 36\n",
            "1912    수학도둑 42\n",
            "Name: Title, dtype: object \n",
            "\n",
            "Cluster 5:\n",
            "218    주류 창업을 위한 주류면허 길라잡이\n",
            "344        생각하는 아이 기다리는 엄마\n",
            "345     우리는 더 많은 민주주의를 원한다\n",
            "350                 공부 추진력\n",
            "351       맛있는 햄버거의 무서운 이야기\n",
            "Name: Title, dtype: object \n",
            "\n",
            "Cluster 6:\n",
            "1711         쿠키런 한자런 7\n",
            "1733      쿠키런 개그 과학 상식\n",
            "1743         쿠키런 한자런 8\n",
            "1837    쿠키런 신대륙에서 찾아라!\n",
            "1898         쿠키런 한자런 6\n",
            "Name: Title, dtype: object \n",
            "\n",
            "Cluster 7:\n",
            "12          강철왕국 프로이센\n",
            "66       쓰레기에 관한 모든 것\n",
            "90     고전 기하학과 현대 기하학\n",
            "153     응용이 보이는 선형대수학\n",
            "266          내부감사 매뉴얼\n",
            "Name: Title, dtype: object \n",
            "\n",
            "Cluster 8:\n",
            "24     로마인 이야기 1-15권 세트\n",
            "93           건축견적이야기 2 \n",
            "94           건축견적이야기 3 \n",
            "357           예수님의 사람 2\n",
            "371      나, 지금 죽어도 좋아 2\n",
            "Name: Title, dtype: object \n",
            "\n",
            "Cluster 9:\n",
            "1024          한국사 편지 세트\n",
            "1724     설민석의 한국사 대모험 5\n",
            "1948     설민석의 한국사 대모험 4\n",
            "5102           한국사 개념사전\n",
            "5646    용선생의 시끌벅적 한국사 9\n",
            "Name: Title, dtype: object \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZNgIwPrcvYTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "similar_words = fasttext_model.wv.most_similar('설민석 ')\n",
        "\n",
        "for word, similarity in similar_words:\n",
        "    print(f\"Word: {word}, similarity : {similarity}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKn4b3l0UBwY",
        "outputId": "4d7601ba-6f7b-4c62-a61b-3136f46b2420"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: 설민석의, similarity : 0.7448292970657349\n",
            "Word: 대모험, similarity : 0.5696137547492981\n",
            "Word: 편지, similarity : 0.49376335740089417\n",
            "Word: 한국사회와, similarity : 0.48239025473594666\n",
            "Word: 혼자다, similarity : 0.4770514965057373\n",
            "Word: 한국사2, similarity : 0.4603557884693146\n",
            "Word: 놀이한국사, similarity : 0.45072123408317566\n",
            "Word: 중국사, similarity : 0.4335116744041443\n",
            "Word: 피트니스, similarity : 0.4328833222389221\n",
            "Word: 한국사회사연구, similarity : 0.4320783019065857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 유사한 단어\n",
        "fasttext_model.wv.most_similar('신사')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nWW_jDum9bK",
        "outputId": "507122af-aa70-4a66-8142-477685fbf259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('언어가', 0.446243554353714),\n",
              " ('독성학', 0.44315633177757263),\n",
              " ('시인은', 0.44257327914237976),\n",
              " ('공작부인', 0.4249315857887268),\n",
              " ('프랑스', 0.4107048809528351),\n",
              " ('공략', 0.4074508547782898),\n",
              " ('배워', 0.4061374068260193),\n",
              " ('활용률', 0.3938716650009155),\n",
              " ('미련한', 0.39299649000167847),\n",
              " ('글방', 0.3900793194770813)]"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Afd-KQHbKerY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}