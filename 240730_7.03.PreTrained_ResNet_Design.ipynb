{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "### 일반 신경망\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "3QmkyfeqyWp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def traditional_nn(input_shape):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "    x = Dense(64, activation='relu')(input_tensor)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    output_tensor = Dense(10, activation='softmax')(x)\n",
        "    model = Model(inputs=input_tensor, outputs=output_tensor)\n",
        "    return model\n",
        "\n",
        "# 입력 텐서 정의\n",
        "  # input_shape : 입력 데이터의 형태 지정 (784,) MNIST 데이터셋(28x28) 평탄화\n",
        "\n",
        "# 1. 64개의 node, 활성화 함수 ReLU\n",
        "# 2. 64개의 node, 활성화 함수 ReLU\n",
        "# 3. 출력 10개의 node\n",
        "\n"
      ],
      "metadata": {
        "id": "DIEg_Uv59F-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l62DhyrLySH4",
        "outputId": "2fd501c0-1a62-4d66-f4e1-8e3b7ebfd86a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 784)]             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                50240     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 55050 (215.04 KB)\n",
            "Trainable params: 55050 (215.04 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 모델 생성\n",
        "model_traditional = traditional_nn((784,))\n",
        "model_traditional.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### ResNet\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, Add, Flatten\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "hEPMx_lGybqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 잔여 블록\n",
        "def residual_block(x, filters, kernel_size=3):\n",
        "    y = Conv2D(filters, kernel_size, padding='same')(x) # 입력 텐서 x에 대해 필터 수와 커널 크기를 지정한 컨볼루션 연산 수행\n",
        "    y = BatchNormalization()(y) # 배치 정규화 -> 학습 안정화\n",
        "    y = ReLU()(y)               # ReLU 활성화 함수 -> 비선형성\n",
        "    y = Conv2D(filters, kernel_size, padding='same')(y) #  첫 번째 컨볼루션의 출력을 입력으로 받아 다시 컨볼루션 연산 수행\n",
        "    y = BatchNormalization()(y)\n",
        "\n",
        "    # 스킵 연결\n",
        "    out = Add()([x, y])  # 입력 텐서 x와 두 번째 컨볼루션의 출력 y를 더함\n",
        "    out = ReLU()(out)\n",
        "    return out\n",
        "\n",
        "# ResNet 모델 정의\n",
        "def resnet(input_shape):\n",
        "    input_tensor = Input(shape=input_shape)  # 입력 데이터의 형태 정의\n",
        "    x = Conv2D(64, (3, 3), padding='same')(input_tensor) # 64 필터 갯수\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    # 잔차 블록 추가\n",
        "    x = residual_block(x, 64) # 64: 필터 갯수\n",
        "        # 잔차 블록 안... 두 개의 Conv2D 레이어와 BatchNormalization, ReLU를 거친 후,\n",
        "        # 입력 x와 더해져 스킵 연결을 통해 최종 출력 out 생성\n",
        "        # 최종 출력 out을 또 다른 잔차 블록으로 전달\n",
        "    x = residual_block(x, 64) # x : Conv2D, BatchNormalization, ReLU를 거친 출력 텐서\n",
        "        # 두개의 잔차 블록 더 복잡한 패턴을 학습, 기울기 소실 문제 완화\n",
        "\n",
        "\n",
        "    # 출력층\n",
        "    x = Flatten()(x) # 2D feature map을 1D 벡터로 변환\n",
        "    x = Dense(10, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=input_tensor, outputs=x)  # 입력과 출력을 지정하여 모델 정의\n",
        "    return model\n",
        "\n",
        "# 모델 생성\n",
        "model_resnet = resnet((32, 32, 3))\n",
        "model_resnet.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Le30K1UuyUdU",
        "outputId": "3248ebb4-3b72-44a7-e2c9-10f39db2ca63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 32, 32, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 32, 32, 64)           1792      ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 32, 32, 64)           256       ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " re_lu (ReLU)                (None, 32, 32, 64)           0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 64)           36928     ['re_lu[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 32, 32, 64)           256       ['conv2d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " re_lu_1 (ReLU)              (None, 32, 32, 64)           0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 32, 32, 64)           36928     ['re_lu_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 32, 32, 64)           256       ['conv2d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 32, 32, 64)           0         ['re_lu[0][0]',               \n",
            "                                                                     'batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " re_lu_2 (ReLU)              (None, 32, 32, 64)           0         ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 32, 32, 64)           36928     ['re_lu_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 32, 32, 64)           256       ['conv2d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " re_lu_3 (ReLU)              (None, 32, 32, 64)           0         ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 32, 32, 64)           36928     ['re_lu_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 32, 32, 64)           256       ['conv2d_4[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 32, 32, 64)           0         ['re_lu_2[0][0]',             \n",
            "                                                                     'batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " re_lu_4 (ReLU)              (None, 32, 32, 64)           0         ['add_1[0][0]']               \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 65536)                0         ['re_lu_4[0][0]']             \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 10)                   655370    ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 806154 (3.08 MB)\n",
            "Trainable params: 805514 (3.07 MB)\n",
            "Non-trainable params: 640 (2.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}